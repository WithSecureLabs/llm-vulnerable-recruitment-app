{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers datasets"
      ],
      "metadata": {
        "id": "uVaV5pVL2oX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFmqtjhx0Kne"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "from datasets import load_metric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "IzSN-bHx024s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load prompt injecction dataset\n",
        "csv_file = 'cv-prompt-injection-dataset.csv'\n",
        "dataset = pd.read_csv(csv_file)\n",
        "dataset = dataset.sample(frac=1, random_state=42)\n",
        "dataset = dataset.reset_index(drop=True)\n",
        "\n",
        "dataset_train = dataset.iloc[:int(0.8 * len(dataset))]\n",
        "dataset_test = dataset.iloc[int(0.8 * len(dataset)):]\n"
      ],
      "metadata": {
        "id": "rsTxV4M2090p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Tokenise the dataset\n",
        "print('Step 2: Tokenise dataset')\n",
        "tokeniser = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_texts = dataset_train['text'].values\n",
        "train_labels = dataset_train['label'].values\n",
        "test_texts =  dataset_test['text'].values\n",
        "test_labels = dataset_test['label'].values\n",
        "\n",
        "train_encodings = tokeniser(list(train_texts), truncation=True, padding=True)\n",
        "test_encodings = tokeniser(list(test_texts), truncation=True, padding=True)\n"
      ],
      "metadata": {
        "id": "PJVKRSd41GD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create dataset class and loaders\n",
        "print('Step 3: Create dataloader')\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "train_dataset = CustomDataset(train_encodings, train_labels)\n",
        "test_dataset = CustomDataset(test_encodings, test_labels)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "PqWHSsr11QMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load BERT model\n",
        "print('Step 4: Load BERT model')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model.to(DEVICE)\n",
        "model.train()\n"
      ],
      "metadata": {
        "id": "7ooUJGe_18jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: train the model using the Trainer API\n",
        "print('Step 5: Begin training using Trainer API')\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=8,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=0.0001,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "results_df = pd.DataFrame(columns=[\"epoch\",\"accuracy\",\"precision\",\"recall\",\"f1\"])\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred # logits are a numpy array, not pytorch tensor\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "def evaluate_model(trainer, epoch):\n",
        "\n",
        "    # Extract predictions and labels\n",
        "    predictions, labels = trainer.predictions.argmax(axis=1), trainer.label_ids\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Calculate precision, recall, and f1 score\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
        "\n",
        "    # Append current metrics to results\n",
        "    global results_df\n",
        "    results_df.loc[len(results_df)] = [epoch, accuracy, precision, recall, f1]\n",
        "\n",
        "    # Return\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    compute_metrics=lambda p: evaluate_model(p, trainer.state.epoch),\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    optimizers=(optim, None) # optimizer and learning rate scheduler\n",
        ")\n"
      ],
      "metadata": {
        "id": "pR3HUajK2Dcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "start_time = time.time()\n",
        "trainer.train()\n",
        "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "r3Z534WW2Gk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uuWew25E9yZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate performance metrics\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "LDqRKHLA_fES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Accuracy\n",
        "def compute_accuracy(model, data_loader, device):\n",
        "    with torch.no_grad():\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(data_loader):\n",
        "\n",
        "        ### Prepare data\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs['logits']\n",
        "            predicted_labels = torch.argmax(logits, 1)\n",
        "            num_examples += labels.size(0)\n",
        "            correct_pred += (predicted_labels == labels).sum()\n",
        "\n",
        "        return correct_pred.float()/num_examples * 100\n",
        "\n",
        "model.eval()\n",
        "model.to(DEVICE)\n",
        "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "id": "kzLRmegB_iKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model to disk\n",
        "trainer.save_model('./models/llm-prompt-injection-detection-800')\n"
      ],
      "metadata": {
        "id": "-gXcxgeaAU6S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}